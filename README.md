---
title: WikiRacing Language Models
emoji: üèÉ
colorFrom: purple
colorTo: gray
sdk: docker
app_port: 7860
hf_oauth: true
hf_oauth_scopes:
  - inference-api
  - email
---

# Can you wikirace faster than an LLM? üèÅ

Go head-to-head with Qwen, Gemma, and DeepSeek on the [Huggingface Space](https://huggingface.co/spaces/HuggingFaceTB/Wikispeedia)

<!-- add gifs -->
![vid2](https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExYW9xbzNjdjNqOTVjb3g1MTE1dHRrbjNjbnpnbnk1anRiMHljZGtlMiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/if50ViyD9dPVSkXTWI/giphy.gif)

Or run 100s of agents on any model in parallel for efficient evaluations [see README](parallel_eval)

![vid1](https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExZ2lua2I4aWxleDUzMzdvdDJ6eGg0YTI3ZTY5OG9pazdid2FkbzF6ayZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/EJQ5j1BwE1gF5hTMoZ/giphy.gif)
